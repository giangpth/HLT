{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"TrainClean.ipynb","provenance":[{"file_id":"1i-V1qYIM-IH4xz6C1-edu6UArTSZb_Uz","timestamp":1634428720597}],"collapsed_sections":[],"authorship_tag":"ABX9TyNoWNdeMWmcu8yeMewaBn7J"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1IF6QfwfVto","executionInfo":{"status":"ok","timestamp":1635607070178,"user_tz":-120,"elapsed":36594,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"b2e53830-bdce-40e0-c212-3d8bd3a05b11"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"X9YD9tCVfff3","executionInfo":{"status":"ok","timestamp":1635607073556,"user_tz":-120,"elapsed":298,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}}},"source":["import numpy as np\n","import pandas as pd\n","import sys\n","import random\n","\n","from tqdm import tqdm\n","\n","import string\n","\n","import os\n","\n","import json"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAOa6iEOfjTl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635607086687,"user_tz":-120,"elapsed":9047,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"ce4c7dc0-5671-437f-8934-d224c7cf80a4"},"source":["!pip install -q transformers"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.1 MB 5.4 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 60.4 MB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 45.1 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 66.8 MB/s \n","\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"id3knqv2flt-","executionInfo":{"status":"ok","timestamp":1635607117871,"user_tz":-120,"elapsed":29770,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}}},"source":["from transformers import AutoTokenizer, BertConfig, TFBertModel"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"u6gkEd7QfniE","executionInfo":{"status":"ok","timestamp":1635607123654,"user_tz":-120,"elapsed":2249,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.losses import sparse_categorical_crossentropy as sce\n","from tensorflow.keras.callbacks import Callback"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9SUoDcHfszO","executionInfo":{"status":"ok","timestamp":1635607126435,"user_tz":-120,"elapsed":511,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}}},"source":["train_ins = '/content/drive/MyDrive/data/fine_data/train_instance_128_clean_975.csv'\n","val_ins = '/content/drive/MyDrive/data/fine_data/val_instance_128_clean.csv'\n","\n","train_squad = '/content/drive/MyDrive/data/fine_data/train_instance_squad.csv'\n","\n","val_id = '/content/drive/MyDrive/data/fine_data/val_id.csv'\n","train_id = '/content/drive/MyDrive/data/fine_data/train_id.csv'\n","\n","val_cand = '/content/drive/MyDrive/data/fine_data/val_mapping.csv'\n","gt = '/content/drive/MyDrive/data/fine_data/validation_long.csv'\n","gt_short = '/content/drive/MyDrive/data/fine_data/validation_short.csv'"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h4rMgm4vhEf_"},"source":["## **Functions to tokenize data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sF7c2xYpk66h","executionInfo":{"status":"ok","timestamp":1635607136796,"user_tz":-120,"elapsed":1159,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"b0592214-80b4-4ad4-f679-70af2fa45b7d"},"source":["model_name = '/content/drive/MyDrive/data/bert_base_uncased'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","tags = [ '``', '\\'\\'', '--']\n","\n","# for i in range(0, 51, 1):\n","#     tags.append(f'[part={i}]')\n","\n","print(tags)\n","\n","special_tokens_dict = {'additional_special_tokens': tags}\n","\n","num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","print(num_added_toks)\n","print(len(tokenizer))\n","\n","# encoder.resize_token_embeddings(len(tokenizer))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['``', \"''\", '--']\n","3\n","30525\n"]}]},{"cell_type":"code","metadata":{"id":"bH-Yx8_qg15G","executionInfo":{"status":"ok","timestamp":1635607142849,"user_tz":-120,"elapsed":8,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}}},"source":["AnswerType = {\n","    'NO_ANSWER': 0,\n","    'YES': 1,\n","    'NO': 2,\n","    'SHORT' : 3,\n","    'LONG' : 4\n","}\n","\n","def preprocess_data(data, tokenizer, debug=False): \n","    progress = tqdm(data, total=len(data))\n","    x1 = []\n","    x2 = []\n","    x3 = []\n","    y = []\n","    for sam in progress:\n","        # part_id = sam['part_id']\n","        # part_tokens = f'[part={part_id}]'\n","\n","        # context = part_tokens + \" \" + sam['context']\n","        tokenized_sam = tokenizer.encode_plus(sam['question'], sam['context'], \n","                                              padding='max_length',\n","                                              truncation=True,\n","                                              max_length=512,\n","                                              add_special_tokens=True)\n","        \n","        x1.append(tf.cast(tokenized_sam['input_ids'], tf.int32))\n","        x2.append(tf.cast(tokenized_sam['token_type_ids'], tf.int32))\n","        x3.append(tf.cast(tokenized_sam['attention_mask'], tf.int32))\n","\n","        y.append([sam['start'], sam['stop'], AnswerType[sam['target']]])\n","\n","    x1 = tf.convert_to_tensor(x1)\n","    x2 = tf.convert_to_tensor(x2)\n","    x3 = tf.convert_to_tensor(x3)\n","\n","    y = tf.convert_to_tensor(y)\n","    return x1, x2, x3, y\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQYWhBBImbjR","executionInfo":{"status":"ok","timestamp":1635328396429,"user_tz":-120,"elapsed":41531,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"62b38b79-a82c-4b6d-c436-30aff6a0edeb"},"source":["train_ins_df = pd.read_csv(train_ins)\n","# train_ins_df = pd.read_csv(train_squad)\n","tran_ins_list = train_ins_df.to_dict('records')\n","print(len(tran_ins_list))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["577571\n"]}]},{"cell_type":"code","metadata":{"id":"eaJLjhPZYKGJ"},"source":["val_id_df = pd.read_csv(val_id)\n","val_id_list = val_id_df['example_id'].tolist()\n","\n","val_cand_df = pd.read_pickle(val_cand)\n","val_cand_list = val_cand_df.to_dict('records') \n","\n","gt_df = pd.read_csv(gt)\n","gt_list = gt_df.to_dict('records')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"datOv8Vxzdqj","executionInfo":{"status":"ok","timestamp":1634462214136,"user_tz":-120,"elapsed":9544,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"61932936-4549-421c-f2ab-ac52f7a968b1"},"source":["val_ins_df = pd.read_csv(val_ins)\n","val_ins_list = val_ins_df.to_dict('records')\n","print(len(val_ins_list))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["169721\n"]}]},{"cell_type":"code","metadata":{"id":"AZBBU6j8l4_q","executionInfo":{"status":"ok","timestamp":1635607144464,"user_tz":-120,"elapsed":4,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}}},"source":["def get_strategy():\n","    try:\n","        tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","        print('Running on TPU ', tpu_cluster_resolver.cluster_spec().as_dict()['worker'])\n","        tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)\n","        tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)\n","        strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)\n","    except ValueError as e:\n","        print(e)\n","        print('No TPU detected')\n","        tpu = None\n","        strategy = tf.distribute.get_strategy()\n","    return strategy"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXnpC6hrnnOZ","executionInfo":{"status":"ok","timestamp":1635607147547,"user_tz":-120,"elapsed":5,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}}},"source":["def create_model(tokenizer, model_name, debug=False):\n","    config = BertConfig()\n","    if debug:\n","        print(config)\n","    # encoder = TFBertModel(config)\n","    encoder = TFBertModel.from_pretrained(model_name)\n","    encoder.resize_token_embeddings(len(tokenizer))\n","\n","    NUM_TARGET = 5\n","    class MyQAModel(tf.keras.Model):\n","        def __init__(self, *inputs, **kwargs):\n","            super().__init__(*inputs, **kwargs)            \n","            self.bert = encoder\n","\n","            # self.dropout_start = tf.keras.layers.Dropout(0.1)\n","            # self.dropout_stop = tf.keras.layers.Dropout(0.1)\n","            # self.dropout_target = tf.keras.layers.Dropout(0.1)\n","\n","            self.start_logits = tf.keras.layers.Dense(1)\n","            self.stop_logits = tf.keras.layers.Dense(1)\n","            \n","            self.target = tf.keras.layers.Dense(NUM_TARGET)\n","\n","        def call(self, inputs, **kwargs):\n","            bert_res=self.bert(inputs[0], \n","                               token_type_ids=inputs[1], \n","                               attention_mask=inputs[2]\n","                               )\n","            \n","            # dropout_res1 = self.dropout_start(bert_res[0])\n","            dropout_res1 = bert_res[0]\n","\n","            start_logits = tf.squeeze(self.start_logits(dropout_res1), -1)\n","\n","            # dropout_res2 = self.dropout_stop(bert_res[0])\n","            dropout_res2 = bert_res[0]\n","\n","            stop_logits = tf.squeeze(self.stop_logits(dropout_res2), -1)\n","\n","            # dropout_res3 = self.dropout_target(bert_res[1])\n","            dropout_res3 = bert_res[1]\n","            \n","            targets = self.target(dropout_res3)\n","            \n","            paddings = tf.constant([[0, 0,], [0, 512-NUM_TARGET]])\n","            targets = tf.pad(targets, paddings)\n","            \n","            res = tf.stack([start_logits, stop_logits, targets], axis=1)\n","            return res\n","        \n","    model = MyQAModel()\n","    return model "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRHAxx2a-6Vt"},"source":["def getFineInsRes(raw_res, ins_list, debug=False):\n","    list_ins_res = []\n","    progress = tqdm(ins_list, total=len(ins_list))\n","    for rowid, row in enumerate(progress):\n","        example_id = row['example_id']\n","        part_id = row['part_id']\n","\n","        res_start = tf.nn.softmax(raw_res[rowid][0]).numpy()\n","        res_stop = tf.nn.softmax(raw_res[rowid][1]).numpy()\n","        res_target = tf.nn.softmax(raw_res[rowid][2]).numpy()\n","        \n","        start = np.argmax(res_start)\n","        stop = np.argmax(res_stop)\n","        target = np.argmax(res_target)\n","\n","        start_score = res_start[start]\n","        stop_score = res_stop[stop]\n","\n","        start_CLS = res_start[0]\n","        stop_CLS = res_stop[0]\n","        \n","        ins_res = {}\n","        ins_res['example_id'] = example_id\n","        ins_res['part_id'] = part_id\n","\n","        ins_res['start'] = start \n","        ins_res['stop'] = stop\n","        ins_res['target'] = target\n","\n","        ins_res['start_score'] = start_score\n","        ins_res['stop_score'] = stop_score\n","        \n","        ins_res['start_CLS'] = start_CLS\n","        ins_res['stop_CLS'] = stop_CLS\n","        if debug:\n","            if rowid == 101:\n","                print(row)\n","                print(ins_res)\n","        list_ins_res.append(ins_res)\n","    list_ins_res_df = pd.DataFrame(list_ins_res)\n","    return list_ins_res_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_uCeKhKCF5-"},"source":["def mergeDocumentRes(ins_df, val_id_df, threshold=0.0001, debug=False):\n","    STRIDE = 128\n","    list_doc_lan = []\n","    for idx, doc in val_id_df.iterrows():\n","        doc_id = doc['example_id']\n","        ins_of_doc = ins_df.loc[ins_df['example_id'] == doc_id]\n","        \n","        start_ins = ins_of_doc.loc[ins_of_doc['start'] != 0]\n","        stop_ins = ins_of_doc.loc[ins_of_doc['stop'] != 0]\n","        all_non_zero = pd.concat([start_ins,stop_ins]).drop_duplicates()\n","        \n","        best_start = -1\n","        best_stop = -1\n","        best_target = 0\n","        best_score = threshold\n","                    \n","        for idx_ins, ins in all_non_zero.iterrows():\n","            ins_start = int(ins['start'])\n","            ins_stop = int(ins['stop'])\n","            ins_target = int(ins['target'])\n","            \n","            part_id = ins['part_id']\n","            part_start = part_id*STRIDE\n","            \n","            real_start = int(ins_start + part_start)\n","            real_stop = int(ins_stop + part_start)\n","            \n","            s_start = ins['start_score']\n","            s_stop = ins['stop_score']\n","            \n","            cls_start = ins['start_CLS']\n","            cls_stop = ins['stop_CLS']\n","            \n","            if real_stop > real_start:   \n","                if s_start - cls_start + s_stop - cls_stop > best_score:\n","                    best_score = s_start - cls_start + s_stop - cls_stop\n","                    best_start = real_start\n","                    best_stop = real_stop\n","                    best_target = ins_target\n","\n","        doc_lan = {}\n","        doc_lan['example_id'] = doc_id\n","        doc_lan['start'] = best_start\n","        doc_lan['stop'] = best_stop\n","        doc_lan['target'] = best_target\n","        doc_lan['score'] = best_score\n","        \n","        if debug:\n","            if idx == 101:\n","                print(doc_lan)\n","        \n","        list_doc_lan.append(doc_lan)\n","    \n","    list_doc_lan_df = pd.DataFrame(list_doc_lan)\n","    return list_doc_lan_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"kom0ftRToCmA","executionInfo":{"status":"ok","timestamp":1634462376481,"user_tz":-120,"elapsed":818,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"8638ade5-b59c-40a2-fc7a-9a81d754d190"},"source":["val_cand_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>example_id</th>\n","      <th>new_candidates</th>\n","      <th>old_candidates</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4158175306918787233</td>\n","      <td>[{'end_token': 169, 'start_token': 6}, {'end_t...</td>\n","      <td>[{'start_token': 8, 'top_level': True, 'end_to...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1957133654292017851</td>\n","      <td>[{'end_token': 138, 'start_token': 24}, {'end_...</td>\n","      <td>[{'start_token': 26, 'top_level': True, 'end_t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1273245364552286191</td>\n","      <td>[{'end_token': 146, 'start_token': 12}, {'end_...</td>\n","      <td>[{'start_token': 14, 'top_level': True, 'end_t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-8663891343543535834</td>\n","      <td>[{'end_token': 188, 'start_token': 64}, {'end_...</td>\n","      <td>[{'start_token': 66, 'top_level': True, 'end_t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8161832609608306276</td>\n","      <td>[{'end_token': 74, 'start_token': 6}, {'end_to...</td>\n","      <td>[{'start_token': 8, 'top_level': True, 'end_to...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             example_id  ...                                     old_candidates\n","0   4158175306918787233  ...  [{'start_token': 8, 'top_level': True, 'end_to...\n","1  -1957133654292017851  ...  [{'start_token': 26, 'top_level': True, 'end_t...\n","2  -1273245364552286191  ...  [{'start_token': 14, 'top_level': True, 'end_t...\n","3  -8663891343543535834  ...  [{'start_token': 66, 'top_level': True, 'end_t...\n","4   8161832609608306276  ...  [{'start_token': 8, 'top_level': True, 'end_to...\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"Qb2hAPxlUmQ2"},"source":["AnswerTypeRev = {\n","    0: 'NO_ANSWER',\n","    1: 'YES',\n","    2: 'NO',\n","    3: 'SHORT',\n","    4: 'LONG'\n","}\n","\n","def getSubmission(doc_res_df, doc_cand_df, threshold=0.0001, debug=False):\n","    doc_res_df.example_id = doc_res_df.example_id.astype(str)\n","    doc_cand_df.example_id = doc_cand_df.example_id.astype(str)\n","    if debug:\n","        print(doc_res_df.dtypes)\n","        print(doc_cand_df.dtypes)\n","\n","    combine_df = pd.merge(doc_res_df, doc_cand_df, on='example_id')\n","    lines = []\n","    for id, doc in combine_df.iterrows():\n","\n","        example_id = doc['example_id']\n","        long_id = str(example_id) + '_long'\n","        short_id = str(example_id) + '_short'\n","\n","        line_long = {}\n","        line_long['example_id'] = long_id\n","\n","        an_start = int(doc['start'])\n","        an_stop = int(doc['stop'])\n","        an_target = doc['target']\n","        an_score = doc['score']\n","        # print(an_start, an_stop, an_target, an_score)\n","        lan_start, lan_stop = -1, -1\n","\n","        # find long answer \n","        if an_start > 0 and an_stop > 0:\n","            candidates = doc['new_candidates']\n","            an_range = [*range(an_start, an_stop + 1, 1)]\n","\n","            best_inter = 0.5\n","            shortest = 10000000000000\n","            best_id = 0\n","            for cidx, cand in enumerate(candidates):\n","                c_start = int(cand['start_token'])\n","                c_stop = int(cand['end_token'])\n","\n","                c_range = [*range(c_start, c_stop + 1, 1)]\n","                inter = len(list(set(an_range)&set(c_range)))\n","            \n","                if float(inter) > best_inter:\n","                    best_id = cidx\n","                    best_inter = inter\n","                    shortest = len(c_range)\n","                elif inter == best_inter:\n","                    if shortest > len(c_range):\n","                        best_id = cidx\n","                        shortest = len(c_range)\n","\n","            real_candidates = doc['old_candidates']\n","            lan_start = real_candidates[best_id]['start_token']\n","            lan_stop = real_candidates[best_id]['end_token']\n","\n","            if debug:\n","                if id == 101:\n","                    print(lan_start, lan_stop)\n","\n","        if lan_start > 0 and lan_stop > 0:\n","            long_string = str(lan_start) + ':' + str(lan_stop)\n","        else:\n","            long_string = ''\n","\n","\n","        line_long['PredictionString'] = long_string\n","        lines.append(line_long)\n","\n","    lines_df = pd.DataFrame(lines)\n","    sorted_df = lines_df.sort_values('example_id')\n","    return sorted_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KS4Kb77Nbyyj"},"source":["def getResult(gt_df, res_df, debug=False):\n","    gt_df.fillna('', inplace=True)\n","    if gt_df.shape[0] != res_df.shape[0]:\n","        print('ERROR: Different number of rows')\n","        return -1.0\n","    \n","    TP, TN, FP, FN = 0, 0, 0, 0\n","\n","    # list_incorrect = []\n","\n","    gt_id = gt_df['example_id'].astype(str).tolist()\n","    res_id = res_df['example_id'].astype(str).tolist()\n","\n","    if gt_id != res_id:\n","        print(\"ERROR: Example_id lists are not the same\")\n","        return -1.0\n","    \n","    gt_res = gt_df['PredictionString'].tolist()\n","    res_res = res_df['PredictionString'].tolist()\n","    id_list = gt_df['example_id'].tolist()\n","    for i in range(len(gt_res)):\n","        if gt_res[i] == res_res[i]:\n","            if gt_res[i] != \"\":\n","                TP += 1\n","            else:\n","                TN += 1\n","        else:\n","            if res_res[i] == '':\n","                FN += 1\n","            else:\n","                FP += 1\n","    recall = float(TP)/float(TP+FN + 0.000001)\n","    precision = float(TP)/float(TP+FP + 0.000001)\n","    print(\"TP: \", TP)\n","    print(\"TN: \", TN)\n","    print(\"FP: \", FP)\n","    print(\"FN: \", FN)\n","    print(\"Recall: \", recall)\n","    print(\"Precision: \", precision)\n","    print(\"F1: \", float(2*recall*precision)/float(recall + precision + 0.00000001))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9d6_Ntq3Btm"},"source":["class IntervalEvaluation(Callback):\n","    def __init__(self, validation_data=(), interval=1):\n","        super(Callback, self).__init__()\n","\n","        self.interval = interval\n","        self.x_val, self.y_val = validation_data\n","        self.list_threshold = [0.0001, 0.001, 0.01, 0.1, 0.15, 0.2]\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        if epoch % self.interval == 0:\n","            y_pred = self.model.predict(self.x_val, verbose=1)\n","            \n","            fineResDf = getFineInsRes(y_pred, val_ins_list)\n","\n","            for threshold in self.list_threshold:\n","                print('THRESHOLD: ', threshold)\n","                docAnsDf = mergeDocumentRes(fineResDf, val_id_df, threshold=threshold)\n","                sub = getSubmission(docAnsDf, val_cand_df)\n","                getResult(gt_df, sub)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOmQEkpPmn99","executionInfo":{"status":"ok","timestamp":1635330245476,"user_tz":-120,"elapsed":1729571,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"582a1b88-a8d9-4261-8c28-2f2b2a0e7135"},"source":["x1, x2, x3, y = preprocess_data(tran_ins_list, tokenizer, debug=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 577571/577571 [28:38<00:00, 336.07it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64ZywoNIzbLW","executionInfo":{"status":"ok","timestamp":1634464865687,"user_tz":-120,"elapsed":475403,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"2ac92a8b-8ac4-43bc-c44b-544874da6565"},"source":["x_val1, x_val2, x_val3, y_val = preprocess_data(val_ins_list, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 169721/169721 [07:52<00:00, 358.91it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdZhJ0UC4ZxK","executionInfo":{"status":"ok","timestamp":1635607428077,"user_tz":-120,"elapsed":133976,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"e14345be-105a-45fc-c297-cda6e8a794ba"},"source":["strategy = get_strategy()\n","weight_path = '/content/drive/MyDrive/data/models/squad/weights-18-0.644.h5'\n","# weight_path=''\n","with strategy.scope():\n","    myQAModel = create_model(tokenizer, model_name)\n","\n","    if os.path.isfile(weight_path):\n","        x = np.ones([1, 512], dtype=int)\n","        myQAModel.predict([x, x, x])\n","        myQAModel.load_weights(weight_path)\n","        myQAModel.summary()\n","    opt = tf.keras.optimizers.Adam(learning_rate=0.00005)\n","    lossSCE = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    metricSCA = tf.keras.metrics.SparseCategoricalAccuracy()\n","    myQAModel.compile(optimizer=opt, loss=lossSCE, metrics=[metricSCA], run_eagerly=False)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"]},{"output_type":"stream","name":"stdout","text":["Running on TPU  ['10.54.131.34:8470']\n","INFO:tensorflow:Clearing out eager caches\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Clearing out eager caches\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.54.131.34:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.54.131.34:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n","Some layers from the model checkpoint at /content/drive/MyDrive/data/bert_base_uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/MyDrive/data/bert_base_uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=int64>]\n","INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=int64>]\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"my_qa_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tf_bert_model (TFBertModel)  multiple                  109484544 \n","_________________________________________________________________\n","dense (Dense)                multiple                  769       \n","_________________________________________________________________\n","dense_1 (Dense)              multiple                  769       \n","_________________________________________________________________\n","dense_2 (Dense)              multiple                  3845      \n","=================================================================\n","Total params: 109,489,927\n","Trainable params: 109,489,927\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"GzinsWtz_-DQ"},"source":["save_locally = tf.train.CheckpointOptions(experimental_io_device='/job:localhost')\n","\n","filepath=\"/content/drive/MyDrive/data/models/current/weights-{epoch:02d}.h5\"\n","checkpoint_dir = os.path.dirname(filepath)\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, \n","                                                verbose=1, \n","                                                save_best_only=False, \n","                                                save_weights_only=True,\n","                                                options=save_locally)\n","# eval = IntervalEvaluation(validation_data=([x_val1, x_val2, x_val3], y_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezt5fjZCpUYf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e14d77c-9a5a-4017-adce-1dae17f37347"},"source":["history = myQAModel.fit(x=[x1, x2, x3],\n","                        y=y,\n","                        batch_size=128,\n","                        # callbacks=[checkpoint, eval], \n","                        callbacks=[checkpoint],\n","                        epochs=20 \n","                        # validation_data=([x_val1, x_val2, x_val3], y_val), \n","                        # validation_batch_size=128,\n","                        )"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=int32>]\n","INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=int32>]\n"]},{"output_type":"stream","name":"stdout","text":["4513/4513 [==============================] - 2199s 468ms/step - loss: 2.0567 - sparse_categorical_accuracy: 0.5450\n","\n","Epoch 00001: saving model to /content/drive/MyDrive/data/models/current/weights-01.h5\n","Epoch 2/20\n","4513/4513 [==============================] - 2060s 456ms/step - loss: 1.5609 - sparse_categorical_accuracy: 0.6050\n","\n","Epoch 00002: saving model to /content/drive/MyDrive/data/models/current/weights-02.h5\n","Epoch 3/20\n","4513/4513 [==============================] - 2061s 457ms/step - loss: 1.3012 - sparse_categorical_accuracy: 0.6490\n","\n","Epoch 00003: saving model to /content/drive/MyDrive/data/models/current/weights-03.h5\n","Epoch 4/20\n","4513/4513 [==============================] - 2062s 457ms/step - loss: 1.1125 - sparse_categorical_accuracy: 0.6852\n","\n","Epoch 00004: saving model to /content/drive/MyDrive/data/models/current/weights-04.h5\n","Epoch 5/20\n","4513/4513 [==============================] - 2063s 457ms/step - loss: 0.9764 - sparse_categorical_accuracy: 0.7136\n","\n","Epoch 00005: saving model to /content/drive/MyDrive/data/models/current/weights-05.h5\n","Epoch 6/20\n","4513/4513 [==============================] - 2064s 457ms/step - loss: 0.8725 - sparse_categorical_accuracy: 0.7364\n","\n","Epoch 00006: saving model to /content/drive/MyDrive/data/models/current/weights-06.h5\n","Epoch 7/20\n","4513/4513 [==============================] - 2064s 457ms/step - loss: 0.7900 - sparse_categorical_accuracy: 0.7557\n","\n","Epoch 00007: saving model to /content/drive/MyDrive/data/models/current/weights-07.h5\n","Epoch 8/20\n","4513/4513 [==============================] - 2065s 457ms/step - loss: 0.7239 - sparse_categorical_accuracy: 0.7717\n","\n","Epoch 00008: saving model to /content/drive/MyDrive/data/models/current/weights-08.h5\n","Epoch 9/20\n","4513/4513 [==============================] - 2065s 458ms/step - loss: 0.6689 - sparse_categorical_accuracy: 0.7854\n","\n","Epoch 00009: saving model to /content/drive/MyDrive/data/models/current/weights-09.h5\n","Epoch 10/20\n","4513/4513 [==============================] - 2065s 458ms/step - loss: 0.6227 - sparse_categorical_accuracy: 0.7972\n","\n","Epoch 00010: saving model to /content/drive/MyDrive/data/models/current/weights-10.h5\n","Epoch 11/20\n","4513/4513 [==============================] - 2065s 458ms/step - loss: 0.5830 - sparse_categorical_accuracy: 0.8080\n","\n","Epoch 00011: saving model to /content/drive/MyDrive/data/models/current/weights-11.h5\n","Epoch 12/20\n","4513/4513 [==============================] - 2065s 458ms/step - loss: 0.5498 - sparse_categorical_accuracy: 0.8173\n","\n","Epoch 00012: saving model to /content/drive/MyDrive/data/models/current/weights-12.h5\n","Epoch 13/20\n","4513/4513 [==============================] - 2065s 458ms/step - loss: 0.5200 - sparse_categorical_accuracy: 0.8260\n","\n","Epoch 00013: saving model to /content/drive/MyDrive/data/models/current/weights-13.h5\n","Epoch 14/20\n","4513/4513 [==============================] - 2065s 457ms/step - loss: 0.4967 - sparse_categorical_accuracy: 0.8324\n","\n","Epoch 00014: saving model to /content/drive/MyDrive/data/models/current/weights-14.h5\n","Epoch 15/20\n","4513/4513 [==============================] - 2065s 458ms/step - loss: 0.4726 - sparse_categorical_accuracy: 0.8398\n","\n","Epoch 00015: saving model to /content/drive/MyDrive/data/models/current/weights-15.h5\n","Epoch 16/20\n","4513/4513 [==============================] - 2066s 458ms/step - loss: 0.4546 - sparse_categorical_accuracy: 0.8455\n","\n","Epoch 00016: saving model to /content/drive/MyDrive/data/models/current/weights-16.h5\n","Epoch 17/20\n","4513/4513 [==============================] - 2067s 458ms/step - loss: 0.4336 - sparse_categorical_accuracy: 0.8517\n","\n","Epoch 00017: saving model to /content/drive/MyDrive/data/models/current/weights-17.h5\n","Epoch 18/20\n","4513/4513 [==============================] - 2064s 457ms/step - loss: 0.4155 - sparse_categorical_accuracy: 0.8575\n","\n","Epoch 00018: saving model to /content/drive/MyDrive/data/models/current/weights-18.h5\n","Epoch 19/20\n","4513/4513 [==============================] - 2063s 457ms/step - loss: 0.4016 - sparse_categorical_accuracy: 0.8621\n","\n","Epoch 00019: saving model to /content/drive/MyDrive/data/models/current/weights-19.h5\n","Epoch 20/20\n","3792/4513 [========================>.....] - ETA: 5:29 - loss: 0.3873 - sparse_categorical_accuracy: 0.8661"]}]},{"cell_type":"markdown","metadata":{"id":"gWW8hSkB32p8"},"source":["## **Train squad**"]},{"cell_type":"code","metadata":{"id":"MaJ1wwVC_70B"},"source":["save_locally = tf.train.CheckpointOptions(experimental_io_device='/job:localhost')\n","\n","\n","filepath=\"/content/drive/MyDrive/data/models/current/weights-{epoch:02d}-{val_sparse_categorical_accuracy:.3f}.h5\"\n","checkpoint_dir = os.path.dirname(filepath)\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, \n","                                                monitor='val_sparse_categorical_accuracy', \n","                                                verbose=1, \n","                                                save_best_only=True, \n","                                                mode='max',\n","                                                save_weights_only=True,\n","                                                options=save_locally)\n","earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sByFyW-436GQ","executionInfo":{"status":"ok","timestamp":1635302641359,"user_tz":-120,"elapsed":12440865,"user":{"displayName":"TRAN HUONG GIANG PHAM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05965413402893494770"}},"outputId":"80a3c29c-0fab-4712-c643-f6feb3f55e63"},"source":["history = myQAModel.fit(x=[x1, x2, x3],\n","                        y=y,\n","                        batch_size=128,\n","                        callbacks=[checkpoint, earlyStop], \n","                        epochs= 100, \n","                        # validation_data=([x_val1, x_val2, x_val3], y_val), \n","                        # validation_batch_size=128)\n","                        validation_split = 0.1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=int32>]\n","INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=int32>]\n"]},{"output_type":"stream","name":"stdout","text":["917/917 [==============================] - ETA: 0s - loss: 2.1526 - sparse_categorical_accuracy: 0.4894"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=int32>]\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r917/917 [==============================] - 604s 558ms/step - loss: 2.1526 - sparse_categorical_accuracy: 0.4894 - val_loss: 1.6904 - val_sparse_categorical_accuracy: 0.5349\n","\n","Epoch 00001: val_sparse_categorical_accuracy improved from -inf to 0.53489, saving model to /content/drive/MyDrive/data/models/current/weights-01-0.535.h5\n","Epoch 2/100\n","917/917 [==============================] - 435s 475ms/step - loss: 1.5403 - sparse_categorical_accuracy: 0.5579 - val_loss: 1.4841 - val_sparse_categorical_accuracy: 0.5717\n","\n","Epoch 00002: val_sparse_categorical_accuracy improved from 0.53489 to 0.57166, saving model to /content/drive/MyDrive/data/models/current/weights-02-0.572.h5\n","Epoch 3/100\n","917/917 [==============================] - 435s 475ms/step - loss: 1.2392 - sparse_categorical_accuracy: 0.6139 - val_loss: 1.3919 - val_sparse_categorical_accuracy: 0.5900\n","\n","Epoch 00003: val_sparse_categorical_accuracy improved from 0.57166 to 0.58996, saving model to /content/drive/MyDrive/data/models/current/weights-03-0.590.h5\n","Epoch 4/100\n","917/917 [==============================] - 435s 475ms/step - loss: 1.0423 - sparse_categorical_accuracy: 0.6566 - val_loss: 1.3480 - val_sparse_categorical_accuracy: 0.6145\n","\n","Epoch 00004: val_sparse_categorical_accuracy improved from 0.58996 to 0.61453, saving model to /content/drive/MyDrive/data/models/current/weights-04-0.615.h5\n","Epoch 5/100\n","917/917 [==============================] - 435s 475ms/step - loss: 0.8999 - sparse_categorical_accuracy: 0.6930 - val_loss: 1.4216 - val_sparse_categorical_accuracy: 0.6117\n","\n","Epoch 00005: val_sparse_categorical_accuracy did not improve from 0.61453\n","Epoch 6/100\n","917/917 [==============================] - 435s 475ms/step - loss: 0.7994 - sparse_categorical_accuracy: 0.7195 - val_loss: 1.4719 - val_sparse_categorical_accuracy: 0.6142\n","\n","Epoch 00006: val_sparse_categorical_accuracy did not improve from 0.61453\n","Epoch 7/100\n","917/917 [==============================] - 435s 475ms/step - loss: 0.7216 - sparse_categorical_accuracy: 0.7410 - val_loss: 1.4135 - val_sparse_categorical_accuracy: 0.6220\n","\n","Epoch 00007: val_sparse_categorical_accuracy improved from 0.61453 to 0.62200, saving model to /content/drive/MyDrive/data/models/current/weights-07-0.622.h5\n","Epoch 8/100\n","917/917 [==============================] - 435s 475ms/step - loss: 0.6664 - sparse_categorical_accuracy: 0.7569 - val_loss: 1.5664 - val_sparse_categorical_accuracy: 0.6147\n","\n","Epoch 00008: val_sparse_categorical_accuracy did not improve from 0.62200\n","Epoch 9/100\n","917/917 [==============================] - 435s 475ms/step - loss: 0.6169 - sparse_categorical_accuracy: 0.7724 - val_loss: 1.5900 - val_sparse_categorical_accuracy: 0.6257\n","\n","Epoch 00009: val_sparse_categorical_accuracy improved from 0.62200 to 0.62568, saving model to /content/drive/MyDrive/data/models/current/weights-09-0.626.h5\n","Epoch 10/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.5760 - sparse_categorical_accuracy: 0.7853 - val_loss: 1.6767 - val_sparse_categorical_accuracy: 0.6319\n","\n","Epoch 00010: val_sparse_categorical_accuracy improved from 0.62568 to 0.63189, saving model to /content/drive/MyDrive/data/models/current/weights-10-0.632.h5\n","Epoch 11/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.5368 - sparse_categorical_accuracy: 0.7981 - val_loss: 1.7078 - val_sparse_categorical_accuracy: 0.6340\n","\n","Epoch 00011: val_sparse_categorical_accuracy improved from 0.63189 to 0.63402, saving model to /content/drive/MyDrive/data/models/current/weights-11-0.634.h5\n","Epoch 12/100\n","917/917 [==============================] - 436s 476ms/step - loss: 0.5055 - sparse_categorical_accuracy: 0.8093 - val_loss: 1.7662 - val_sparse_categorical_accuracy: 0.6365\n","\n","Epoch 00012: val_sparse_categorical_accuracy improved from 0.63402 to 0.63647, saving model to /content/drive/MyDrive/data/models/current/weights-12-0.636.h5\n","Epoch 13/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.4802 - sparse_categorical_accuracy: 0.8188 - val_loss: 1.7518 - val_sparse_categorical_accuracy: 0.6321\n","\n","Epoch 00013: val_sparse_categorical_accuracy did not improve from 0.63647\n","Epoch 14/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.4463 - sparse_categorical_accuracy: 0.8312 - val_loss: 1.8178 - val_sparse_categorical_accuracy: 0.6330\n","\n","Epoch 00014: val_sparse_categorical_accuracy did not improve from 0.63647\n","Epoch 15/100\n","917/917 [==============================] - 435s 475ms/step - loss: 0.4217 - sparse_categorical_accuracy: 0.8406 - val_loss: 1.8168 - val_sparse_categorical_accuracy: 0.6310\n","\n","Epoch 00015: val_sparse_categorical_accuracy did not improve from 0.63647\n","Epoch 16/100\n","917/917 [==============================] - 435s 475ms/step - loss: 0.3937 - sparse_categorical_accuracy: 0.8517 - val_loss: 1.7821 - val_sparse_categorical_accuracy: 0.6376\n","\n","Epoch 00016: val_sparse_categorical_accuracy improved from 0.63647 to 0.63760, saving model to /content/drive/MyDrive/data/models/current/weights-16-0.638.h5\n","Epoch 17/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.3653 - sparse_categorical_accuracy: 0.8625 - val_loss: 1.9661 - val_sparse_categorical_accuracy: 0.6377\n","\n","Epoch 00017: val_sparse_categorical_accuracy improved from 0.63760 to 0.63775, saving model to /content/drive/MyDrive/data/models/current/weights-17-0.638.h5\n","Epoch 18/100\n","917/917 [==============================] - 436s 476ms/step - loss: 0.3467 - sparse_categorical_accuracy: 0.8700 - val_loss: 2.0545 - val_sparse_categorical_accuracy: 0.6437\n","\n","Epoch 00018: val_sparse_categorical_accuracy improved from 0.63775 to 0.64373, saving model to /content/drive/MyDrive/data/models/current/weights-18-0.644.h5\n","Epoch 19/100\n","917/917 [==============================] - 436s 476ms/step - loss: 0.3187 - sparse_categorical_accuracy: 0.8816 - val_loss: 2.0969 - val_sparse_categorical_accuracy: 0.6350\n","\n","Epoch 00019: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 20/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.2940 - sparse_categorical_accuracy: 0.8919 - val_loss: 2.0163 - val_sparse_categorical_accuracy: 0.6387\n","\n","Epoch 00020: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 21/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.2703 - sparse_categorical_accuracy: 0.9009 - val_loss: 1.9786 - val_sparse_categorical_accuracy: 0.6345\n","\n","Epoch 00021: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 22/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.2440 - sparse_categorical_accuracy: 0.9112 - val_loss: 2.1498 - val_sparse_categorical_accuracy: 0.6394\n","\n","Epoch 00022: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 23/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.2227 - sparse_categorical_accuracy: 0.9199 - val_loss: 2.0512 - val_sparse_categorical_accuracy: 0.6400\n","\n","Epoch 00023: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 24/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.2026 - sparse_categorical_accuracy: 0.9280 - val_loss: 2.1786 - val_sparse_categorical_accuracy: 0.6339\n","\n","Epoch 00024: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 25/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.1821 - sparse_categorical_accuracy: 0.9360 - val_loss: 2.2795 - val_sparse_categorical_accuracy: 0.6291\n","\n","Epoch 00025: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 26/100\n","917/917 [==============================] - 436s 475ms/step - loss: 0.1679 - sparse_categorical_accuracy: 0.9413 - val_loss: 2.3189 - val_sparse_categorical_accuracy: 0.6219\n","\n","Epoch 00026: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 27/100\n","917/917 [==============================] - 438s 478ms/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9462 - val_loss: 2.3015 - val_sparse_categorical_accuracy: 0.6247\n","\n","Epoch 00027: val_sparse_categorical_accuracy did not improve from 0.64373\n","Epoch 28/100\n","917/917 [==============================] - 435s 475ms/step - loss: 0.1424 - sparse_categorical_accuracy: 0.9509 - val_loss: 2.3367 - val_sparse_categorical_accuracy: 0.6234\n","\n","Epoch 00028: val_sparse_categorical_accuracy did not improve from 0.64373\n"]}]},{"cell_type":"code","metadata":{"id":"Q6dPat784Ayz"},"source":[""],"execution_count":null,"outputs":[]}]}